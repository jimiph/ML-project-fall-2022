{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5902c1f3",
   "metadata": {},
   "source": [
    "<img src='http://www-scf.usc.edu/~ghasemig/images/sharif.png' alt=\"SUT logo\" width=200 height=200 align=left class=\"saturate\" >\n",
    "\n",
    "<br>\n",
    "<font face=\"Times New Roman\">\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "    Fall 2022<br>\n",
    "<font color=3C99D size=5>\n",
    "    Project <br>\n",
    "<font color=696880 size=4>\n",
    "    Project Team \n",
    "    \n",
    "    \n",
    "____\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e85f16a",
   "metadata": {},
   "source": [
    "### Full Name : \n",
    "### Student Number : \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df5e74",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a627177",
   "metadata": {},
   "source": [
    "In this project, we are going to have a brief and elementary hands-on real-world project, predicting breast cancer survival using machine learning models with clinical data and gene expression profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e52cbc",
   "metadata": {},
   "source": [
    "# Data Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254cb90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-29T19:31:29.604891Z",
     "start_time": "2023-01-29T19:31:29.601061Z"
    }
   },
   "source": [
    "For this purpose, we will use \"Breast Cancer Gene Expression Profiles (METABRIC)\" data. \n",
    "The first 31 columns of data contain clinical information including death status.\n",
    "The next columns of the data contain gene's related information which includes both gene expressions and mutation information. (gene's mutation info columns have been marked with \"_mut\" at the end of the names of the columns) \n",
    "For more information please read the [data documentation](https://www.kaggle.com/datasets/raghadalharbi/breast-cancer-gene-expression-profiles-metabric)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef1d4a",
   "metadata": {},
   "source": [
    "# Data Preparation (15 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3240d5d",
   "metadata": {},
   "source": [
    "In this section you must first split data into three datasets:\n",
    "<br>\n",
    "1- clinical dataset\n",
    "<br>\n",
    "2- gene expressions dataset\n",
    "<br>\n",
    "3- gene mutation dataset. (We will not use this dataset in further steps of the project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42f2b1",
   "metadata": {},
   "source": [
    "## Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463b243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def suffix_remove(text, suffix='_mut'):\n",
    "    check_last = suffix + '\\n'\n",
    "    if text[len(text)-len(suffix): len(text)] == suffix or \\\n",
    "        text[len(text)-len(check_last) : len(text)] == check_last:\n",
    "        return ''\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "file_name = 'METABRIC_RNA_Mutation.csv'\n",
    "\n",
    "with open (file_name, 'r') as file:\n",
    "    headers = file.readline()\n",
    "    headers = np.array([suffix_remove(head) for head in headers.split(',')])\n",
    "    total_head_num = len(headers)\n",
    "    headers = headers[np.nonzero(headers)]\n",
    "\n",
    "dataset = np.loadtxt(file_name, delimiter=',', skiprows=1, dtype='U')\n",
    "\n",
    "clinical_cols = np.arange(0, 31)\n",
    "gene_expressions_cols = np.arange(31, len(headers))\n",
    "gene_mutation_cols = np.arange(len(headers), total_head_num)\n",
    "clinical_gen_cols = np.arange(0, len(headers))\n",
    "\n",
    "clinical_dataset = dataset[:, clinical_cols]\n",
    "gen_expressions_dataset = dataset[:, gene_expressions_cols]\n",
    "gene_mutation_dataset = dataset[:, gene_mutation_cols]\n",
    "clinical_gen_dataset = dataset[:, clinical_gen_cols]\n",
    "\n",
    "clinical_header = headers[0: 31]\n",
    "gene_expressions_header = headers[31: len(headers)]\n",
    "clinical_gen_header = headers\n",
    "categorical_features = ['type_of_breast_surgery', 'cancer_type', 'cancer_type_detailed',\n",
    "'cellularity', 'pam50_+_claudin-low_subtype', 'er_status_measured_by_ihc', 'er_status', \n",
    "'neoplasm_histologic_grade', 'her2_status_measured_by_snp6', 'her2_status', 'tumor_other_histologic_subtype',\n",
    "'inferred_menopausal_state', 'integrative_cluster', 'primary_tumor_laterality', 'oncotree_code',\n",
    "'pr_status', '3-gene_classifier_subtype', 'death_from_cancer']\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('clinical_dataset.csv', clinical_dataset, delimiter=',', fmt='%s')\n",
    "np.savetxt('gen_expressions_dataset.csv', gen_expressions_dataset, delimiter=',', fmt='%s')\n",
    "np.savetxt('gene_mutation_dataset.csv', gene_mutation_dataset, delimiter=',', fmt='%s')\n",
    "np.savetxt('clinical_gen_dataset.csv', clinical_gen_dataset, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebfdb6b",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d59d7",
   "metadata": {},
   "source": [
    "For each dataset, you must perform a sufficient EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3815455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_clinical_gen = pd.read_csv('clinical_gen_dataset.csv', names=clinical_gen_header)\n",
    "\n",
    "\n",
    "df_clinical = df_clinical_gen.iloc[:, 0:31]\n",
    "df_gen_expression = df_clinical_gen.iloc[:, 31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184f6e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b015815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen_expression.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fe7f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical_gen.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d94e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                          0\n",
       "age_at_diagnosis                    0\n",
       "type_of_breast_surgery             22\n",
       "cancer_type                         0\n",
       "cancer_type_detailed               15\n",
       "cellularity                        54\n",
       "chemotherapy                        0\n",
       "pam50_+_claudin-low_subtype         0\n",
       "cohort                              0\n",
       "er_status_measured_by_ihc          30\n",
       "er_status                           0\n",
       "neoplasm_histologic_grade          72\n",
       "her2_status_measured_by_snp6        0\n",
       "her2_status                         0\n",
       "tumor_other_histologic_subtype     15\n",
       "hormone_therapy                     0\n",
       "inferred_menopausal_state           0\n",
       "integrative_cluster                 0\n",
       "primary_tumor_laterality          106\n",
       "lymph_nodes_examined_positive       0\n",
       "mutation_count                     45\n",
       "nottingham_prognostic_index         0\n",
       "oncotree_code                      15\n",
       "overall_survival_months             0\n",
       "overall_survival                    0\n",
       "pr_status                           0\n",
       "radio_therapy                       0\n",
       "3-gene_classifier_subtype         204\n",
       "tumor_size                         20\n",
       "tumor_stage                       501\n",
       "death_from_cancer                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ea47ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brca1      0\n",
       "brca2      0\n",
       "palb2      0\n",
       "pten       0\n",
       "tp53       0\n",
       "          ..\n",
       "tnk2       0\n",
       "tulp4      0\n",
       "ugt2b15    0\n",
       "ugt2b17    0\n",
       "ugt2b7     0\n",
       "Length: 489, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen_expression.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3e7381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                 0\n",
       "age_at_diagnosis           0\n",
       "type_of_breast_surgery    22\n",
       "cancer_type                0\n",
       "cancer_type_detailed      15\n",
       "                          ..\n",
       "tnk2                       0\n",
       "tulp4                      0\n",
       "ugt2b15                    0\n",
       "ugt2b17                    0\n",
       "ugt2b7                     0\n",
       "Length: 520, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinical_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff00c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handling missing values.\n",
    "\"\"\"\n",
    "\n",
    "df_clinical_gen.dropna(inplace=True)\n",
    "# df_clinical_gen.interpolate(method='linear', limit_direction='backward', inplace=True)\n",
    "df_clinical = df_clinical_gen.iloc[:, 0:31]\n",
    "df_gen_expression = df_clinical_gen.iloc[:, 31:]\n",
    "df_clinical.index = [i for i in range(df_clinical.shape[0])]\n",
    "df_gen_expression.index = [i for i in range(df_clinical.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handling categorical features in clinical dataset and removing target column and 'death_from_cancer'\n",
    "from clinical dataframe.\n",
    "\"\"\"\n",
    "target_name = \"overall_survival\"\n",
    "should_remove_name = \"death_from_cancer\"\n",
    "\n",
    "target = df_clinical[target_name]\n",
    "\n",
    "df_clinical.drop(columns=[should_remove_name], axis=1, inplace=True)\n",
    "df_clinical.drop(columns=[target_name], axis=1, inplace=True)\n",
    "\n",
    "categorical_features_info = {}\n",
    "for feature in categorical_features:\n",
    "    items = []\n",
    "    for item in df_clinical_gen[feature].unique():\n",
    "        if pd.notnull(item):\n",
    "            items.append(item)\n",
    "    categorical_features_info[feature] = items\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "clinical_header_final = [feature for feature in clinical_header if (feature!=target_name and feature!=should_remove_name)]\n",
    "\n",
    "def apply_onehotencoding(df, categorical_features_info):\n",
    "    finad_df = pd.DataFrame()\n",
    "    for feature in clinical_header_final:\n",
    "        if feature in categorical_features_info.keys():\n",
    "            encoder_df = pd.DataFrame(encoder.fit_transform(df[[feature]]).toarray())\n",
    "            cols = [feature+':'+str(category) for category in categorical_features_info[feature]]\n",
    "            encoder_df.columns = cols\n",
    "            finad_df[cols] = encoder_df\n",
    "        else:\n",
    "            finad_df[feature] = df[[feature]]\n",
    "    return finad_df\n",
    "encoded_df_clinical = apply_onehotencoding(df_clinical, categorical_features_info)\n",
    "encoded_df_clinical.to_csv('encoded_df_clinical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3821f",
   "metadata": {},
   "source": [
    "## Dimension Reduction (20 + Up to 10 Points Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925e2cf",
   "metadata": {},
   "source": [
    "For each dataset, investigate whether it is needed to use a dimensionality reduction approach or not. If yes, please reduce the dataset's dimension. You can use UMAP for this purpose but any other approach is acceptable. Finding the most important features contains extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "259a3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "\"\"\"\n",
    "Since most of the features in clinical dataset are categorical (the 18 out of 31) it is\n",
    "not needed to apply dimensionality reduction on it. But for the gen expression dataset\n",
    "we deal with many numeric features (489 features); thus a dimensionality reduction process\n",
    "is required.\n",
    "\"\"\"\n",
    "n_features_gen = 30\n",
    "n_features_tot = n_features_gen + 31\n",
    "pca_reducer = PCA(n_components=n_features_gen)\n",
    "df_reduced_gen_expression = pca_reducer.fit_transform(df_gen_expression)\n",
    "df_reduced_gen_expression = pd.DataFrame(df_reduced_gen_expression)\n",
    "\n",
    "df_reduced_encoded_clinical_gen = pd.concat([encoded_df_clinical, df_reduced_gen_expression], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2aba282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(873, 106)\n",
      "(219, 106)\n",
      "(873, 1)\n",
      "(219, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def splitter(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitter(df_reduced_encoded_clinical_gen, target)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ea4bb",
   "metadata": {},
   "source": [
    "# Classic Model (25 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c5d75",
   "metadata": {},
   "source": [
    "In this section, you must implement a classic classification model for clinical, gene expressions, and reduced gene expressions datasets. Using Random Forest is suggested. (minimum acceptable accuracy = 60%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ec1dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_forest': 0.7397260273972602, 'extra_tree': 0.776255707762557, 'decision_tree': 0.6118721461187214, 'adaboost': 0.6894977168949772, 'svc': 0.5707762557077626}\n",
      "{'random_forest': {'n_estimators': 30, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_leaf_nodes': 8, 'max_features': None, 'max_depth': 2}, 'extra_tree': {'n_estimators': 90, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_leaf_nodes': 6, 'max_features': None, 'max_depth': 8, 'criterion': 'log_loss'}, 'decision_tree': {'min_samples_split': 7, 'min_samples_leaf': 2, 'max_leaf_nodes': 6, 'max_features': 'log2', 'max_depth': 3, 'criterion': 'entropy'}, 'adaboost': {'n_estimators': 50, 'learning_rate': 0.005}, 'svc': {'kernel': 'rbf', 'gamma': 'scale', 'degree': 1}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "class classical_models():\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.best_params_models_dict = {}\n",
    "\n",
    "    def hyperparameter_tuning(self, model, random_grid_dic, model_name):\n",
    "        classifier = RandomizedSearchCV(estimator=model, param_distributions=random_grid_dic, n_iter=1, cv=3, \n",
    "        verbose=0, random_state=0, n_jobs=-1)\n",
    "        classifier.fit(self.X_train, self.y_train.ravel())\n",
    "        best_params = classifier.best_params_\n",
    "        self.best_params_models_dict[model_name] = best_params\n",
    "        return best_params\n",
    "    \n",
    "    def random_forest(self):\n",
    "        random_grid = {'n_estimators': [10*i for i in range(1, 11)],\n",
    "                    'max_features': ['log2', 'sqrt', None],\n",
    "                    'max_leaf_nodes': range(5, 10),\n",
    "                    'max_depth': range(2, 10),\n",
    "                    'min_samples_split': range(5, 10),\n",
    "                    'min_samples_leaf': range(0, 4)\n",
    "                    }\n",
    "        best_params = self.hyperparameter_tuning(RandomForestClassifier(), random_grid, 'random_forest')\n",
    "        classifier = RandomForestClassifier(**best_params)\n",
    "        classifier.fit(self.X_train, self.y_train.ravel())\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def extra_tree(self):\n",
    "        random_grid = {'n_estimators': [10*i for i in range(1, 11)],\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_features': ['log2', 'sqrt', None],\n",
    "            'max_leaf_nodes': range(5, 10),\n",
    "            'max_depth': range(2, 10),\n",
    "            'min_samples_split': range(5, 10),\n",
    "            'min_samples_leaf': range(0, 4)\n",
    "            }\n",
    "        best_params = self.hyperparameter_tuning(ExtraTreesClassifier(), random_grid, 'extra_tree')\n",
    "        classifier = ExtraTreesClassifier(**best_params)\n",
    "        classifier.fit(self.X_train, self.y_train.ravel())\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def decision_tree(self):\n",
    "        random_grid = {\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_features': ['log2', 'sqrt', None],\n",
    "            'max_leaf_nodes': range(5, 10),\n",
    "            'max_depth': range(2, 10),\n",
    "            'min_samples_split': range(5, 10),\n",
    "            'min_samples_leaf': range(0, 4)\n",
    "            }\n",
    "        best_params = self.hyperparameter_tuning(DecisionTreeClassifier(), random_grid, 'decision_tree')\n",
    "        classifier = DecisionTreeClassifier(**best_params)\n",
    "        classifier.fit(self.X_train, self.y_train.ravel())\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def adaboost(self):\n",
    "        if self.best_params_models_dict['decision_tree']:\n",
    "            random_grid = {'n_estimators': [10*i for i in range(1, 11)],\n",
    "                'learning_rate': [0.001*i for i in range(1, 11)],\n",
    "                }\n",
    "            best_params = self.hyperparameter_tuning(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(**self.best_params_models_dict['decision_tree'])),\n",
    "                                                    random_grid, 'adaboost')\n",
    "            classifier = AdaBoostClassifier(**best_params)\n",
    "            classifier.fit(self.X_train, self.y_train.ravel())\n",
    "            y_pred = classifier.predict(self.X_test)\n",
    "            return y_pred\n",
    "        else:\n",
    "            self.decision_tree()\n",
    "\n",
    "\n",
    "    def svc(self):\n",
    "        random_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "            'degree': range(1, 10),\n",
    "            'gamma': ['scale', 'auto']\n",
    "            }\n",
    "        best_params = self.hyperparameter_tuning(SVC(), random_grid, 'svc')\n",
    "        classifier = SVC(**best_params)\n",
    "        classifier.fit(self.X_train, self.y_train.ravel())\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        return y_pred\n",
    "\n",
    "classical = classical_models(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "y_pred_random_forest = classical.random_forest()\n",
    "y_pred_extra_tree = classical.extra_tree()\n",
    "y_pred_decision_tree = classical.decision_tree()\n",
    "y_pred_adaboost = classical.adaboost()\n",
    "y_pred_svc = classical.svc()\n",
    "\n",
    "accuracy_score_dict = {'random_forest': accuracy_score(y_pred_random_forest, y_test),\n",
    "'extra_tree': accuracy_score(y_pred_extra_tree, y_test),\n",
    "'decision_tree': accuracy_score(y_pred_decision_tree, y_test),\n",
    "'adaboost': accuracy_score(y_pred_adaboost, y_test),\n",
    "'svc': accuracy_score(y_pred_svc, y_test)}\n",
    "\n",
    "print(accuracy_score_dict)\n",
    "print(classical.best_params_models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50146d67",
   "metadata": {},
   "source": [
    "# Neural Network (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c4047",
   "metadata": {},
   "source": [
    "In this section, you must implement a neural network model for clinical, gene expressions and reduced gene expressions datasets. Using the MPL models is suggested. (minimum acceptable accuracy = 60%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2992ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671232876712328\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(alpha=1e-3,\n",
    "                     hidden_layer_sizes=(20, 15, 10, 5), random_state=1, max_iter=1000)\n",
    "\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56877dc4",
   "metadata": {},
   "source": [
    "# Model Comparison (10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe56a",
   "metadata": {},
   "source": [
    "Compare different models and different datasets (clinical, gene expressions, and gene reduced expressions) and try to explain their differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f05a73",
   "metadata": {},
   "source": [
    "#### \\# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "91b410dd9a8bb11c536d001ad40742c19c082a60dfe79daca26509b38e876541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
